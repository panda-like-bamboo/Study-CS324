# 大模型理论基础学习笔记——第3，4章 危害，与模型架构

这一章比较奇怪，cs324讲述了危害性，但是中文文档却没有，讲的是架构方面的内容。所以本篇笔记先非常简略的说一下危害性，之后再讲架构方面的内容。

## **一、危害性部分：**

**1. 危害探讨**

在这一部分，我们对大型语言模型可能引发的多方面危害进行了探讨。这些危害涉及性能不同群体、社会偏见、毒性、虚假信息、安全与隐私、版权法律、环境影响和权力集中等方面。

**2. 新兴技术中的危害**

我们强调了模型能力和危害之间的紧密关系，指出提升能力可能导致更广泛采用，从而增加总体危害。

**3. 危害与安全伦理在其他领域的思考**

我们提及了贝尔蒙特报告和IRB，生物伦理学和CRISPR，以及FDA和食品安全等作为其他领域处理危害和安全伦理的例子。

**4. 社会群体**

我们讨论了识别社会群体的方法，包括生产者、受众和内容等方面，以及受保护属性和历史性边缘化的概念。

**5. 性能差异和社会偏见的例子**

我们提供了具体案例，如名字文物和大型语言模型对穆斯林的关联，以展示性能差异和社会偏见的实际问题。

**6. 测量和其他考虑**

我们引入了公平度量和测量偏见的概念，讨论了测量偏见时的设计决策，以及对现有基准的批评。

**7. 决策和展望**

最后，我们指出了现有方法对减轻危害的不足，并提出社会技术方法可能是减轻危害的有效途径。

总体来说，我们深入研究了大型语言模型可能引发的各种危害，强调了与性能、社会偏见、安全伦理等相关的重要概念。


## 二、架构
## 第3章 模型架构

### **3.2 分词**

#### **3.2.1 基于空格的分词**

分词是将文本序列转换为词元序列的过程，其中词元可以是单词、标点符号等。英文通常通过空格分词，但其他语言可能没有明显的分隔符，如中文。

#### **3.2.2 Byte Pair Encoding (BPE) 分词算法**

**Byte Pair Encoding (BPE) 分词算法**

**概要：** BPE是一种用于分词的算法，最初在数据压缩领域应用，后来广泛用于自然语言处理。其主要思想是通过学习数据中常见的字节对，逐步构建更有语言学意义的词汇表。

**步骤：**

1. **初始化：** 将每个字符视为一个初始词元，构建初始的词汇表V。
   - 例如，对于输入语料：[['abab', 'abcab', 'abcaab']]，初始词汇表为：V = ['a', 'b', 'c']。

2. **迭代过程：**
   - **找到共同出现次数最多的元素对：** 在当前词汇表V中，找到共同出现次数最多的元素对。
   - **替换和更新：** 将找到的元素对替换为新符号，并更新序列和词汇表。
   - **重复以上步骤直到满足停止条件。**

**示例：**

考虑输入语料：[['abab', 'abcab', 'abcaab']]。

**第一次迭代：**
- **共同出现最多的元素对：** 'ab'。
- **替换和更新：** 将'ab'替换为新符号'x'，得到更新后的序列和词汇表。
- **更新后的序列：** [['x', 'x', 'abcab', 'axcaax']]
- **更新后的词汇表：** V = ['a', 'b', 'c', 'x']

**第二次迭代：**
- **共同出现最多的元素对：** 'ax'。
- **替换和更新：** 将'ax'替换为新符号'y'，得到更新后的序列和词汇表。
- **更新后的序列：** [['xy', 'xy', 'abcab', 'ycaay']]
- **更新后的词汇表：** V = ['a', 'b', 'c', 'x', 'y']

**继续迭代，直到满足停止条件。** 在每次迭代中，BPE算法通过发现并合并频繁共现的字节对，逐渐演化词汇表，使其能够更好地捕捉语言结构，特别适用于处理没有空格分隔的语言。




##### 3.2.2.1 Unicode的问题
在多语言环境中，Unicode字符的数量庞大，为了减少数据稀疏性，可以在字节级别而不是Unicode字符级别上运行BPE算法。

**Unicode问题与BPE分词的解决方案**

*问题描述：* Unicode是一种包含大量字符的编码标准，而在训练数据中不可能涵盖所有Unicode字符。这导致了数据的稀疏性，增加了模型的难度。特别在多语言环境中，不同语言的Unicode字符更加丰富多样，给自然语言处理任务带来了挑战。

*解决方案：* 为了应对Unicode字符的多样性和减少数据的稀疏性，可以使用Byte Pair Encoding (BPE) 分词算法，并将其应用于字节级别而不是Unicode字符级别。

*具体步骤：*
1. **Unicode字符表示：** 将Unicode字符表示为其字节编码。每个Unicode字符通常由多个字节组成，而将其表示为字节序列可以更好地处理多语言数据。

   例如，将中文字符 "今天" 表示为字节序列：[x62, x11, 4e, ca]。

2. **BPE分词：** 在字节级别运行BPE算法。该算法会发现并合并频繁共现的字节对，形成新的符号，从而减少数据中出现的低频词汇。

   以 "今天" 为例，可能在BPE过程中会发现 'x62' 和 'x11' 经常共同出现，于是合并为一个新符号，得到更新后的字节序列。

   更新后的字节序列：[新符号, 4e, ca]

   这个过程的目标是减少数据的稀疏性，提高模型在多语言环境中的泛化能力。

*优势与作用：*
- **处理多语言环境：** 通过字节级别的表示和BPE分词，可以更好地适应不同语言之间的字符差异，使模型更具鲁棒性。
- **减少稀疏性：** 对字节级别进行分词可以减少数据中出现的低频词汇，使得模型更容易学习通用的语言结构，而不受稀疏数据的干扰。
3.2.3 Unigram model (SentencePiece)
Unigram模型是一种更“有原则”的分词方法，通过定义目标函数来捕捉良好分词的特征。
通过统计每个词汇在训练数据中的出现次数来估计其概率，通过EM算法进行优化。


#### **3.2.3 Unigram模型与算法流程**

**简介**

这个模型的原理是观察每个单词在一段文字中的频率，并根据这些频率判断文本分成的每个部分是否合理。例如，对于文本“ababc”，Unigram模型可能会认为“ab”出现的次数较多，因此在分词时更可能将“ab”作为一个单词。

Unigram模型的灵活性使其适用于不同的语言和任务。由于它主要关注单词的频率，而不依赖于复杂的语法规则，因此可用于处理多语言环境和各种文本数据。

**数据稀疏性处理**

在实际的文本数据中，Unigram模型通过...

**Unigram模型介绍**

在分词任务中，Unigram模型提出了一种更有原则的方法。该模型使用目标函数捕捉好的分词特征，以适应更多的分词场景。核心思想是通过定义每个词汇在训练数据中...

**示例分析**

以训练数据 "𝖺𝖻𝖺𝖻𝖼ababc" 为例，Unigram模型的分词结果为：{("𝖺", "𝖻"), ("𝖺", "𝖻"), ("𝖼")}

对应的词汇表为：{"𝖺𝖻", "𝖼"}，表示训练数据中出现的所有词汇。Unigram模型通过统计每个词汇在训练数据中的出现次数来估计其概率。在这个例子中...

**算法流程**

1. 从一个较大的种子词汇表开始。
2. 使用EM算法优化Unigram模型中的目标函数。
3. 计算每个词汇的loss，衡量如果将该词汇从词汇表中移除，似然值会减少多少。
4. 按照loss进行排序，并保留词汇表中排名靠前的80%的词汇。
5. 重复迭代上述步骤，逐渐优化词汇表，剔除对似然值贡献较小的词汇，减少数据的稀疏性，提高模型效果。

这个流程的目标是通过迭代优化和剪枝，逐渐演化词汇表，保留那些对于似然值有较大贡献的词汇，提升模型的性能。通过Unigram模型，分词模型在训练过程中更加有原则地调整词汇表，使得分词结果更加符合语言结构。


### **3.3 模型架构**

#### **3.3.0 上下文表征向量：**
采用避免生成整个序列的生成模型的方法，使用上下文表征向量。上下文向量表征是在自然语言处理中常用的概念，涉及将一个词元或一段文本嵌入到一个向量空间中，以便在模型中进行进一步的处理。在语言模型中，上下文向量表征尤其重要，因为它带有词元周围上下文的信息，有助于模型更好地理解词元的语境。

**上下文向量表征的要点：**
1. **定义：** 上下文向量表征是一个向量，表示一个词元或一段文本在其上下文中的语义信息。
2. **嵌入函数：** 通常，上下文向量表征通过嵌入函数（embedding function）生成。这个函数将词元或文本映射到一个低维向量空间中，使得相似的语义概念在向量空间中距离较近。
3. **依赖上下文：** 上下文向量表征的生成依赖于词元周围的上下文，即周围的其他词元。这种上下文信息有助于更好地理解词元在特定语境中的含义。
4. **双向依赖：** 在某些情况下，上下文向量表征可以双向地依赖于左侧和右侧的上下文，使得模型能够考虑到整个文本的语境。
5. **任务特定：** 上下文向量表征的生成可以针对不同的任务，例如分类、情感分析、生成等。生成的向量可以作为输入传递给其他模型组件，以执行特定任务。

**在上下文向量表征中的应用场景：**
- **情感分析：** 在分析一段文本的情感时，上下文向量表征可以捕捉到词元的情感色彩，并考虑其在上下文中的影响。
- **生成任务：** 在文本生成任务中，上下文向量表征可以作为模型生成下一个词元的输入，确保生成的文本与其上下文一致。
- **自然语言理解：** 在理解任务中，上下文向量表征有助于模型更全面地理解文本的语义结构和关系。

总体而言，上下文向量表征是自然语言处理中用于捕捉语境信息的重要工具，提供了对词元或文本在其上下文中语义含义的更深刻理解。

### **3.3.1 语言模型分类**

**起源和发展：**
语言模型最初源自Transformer模型，这是一种编码-解码（Encoder-Decoder）架构。当前，语言模型被划分为三个类型：编码端（Encoder-Only）、解码端（Decoder-Only）和编码-解码端（Encoder-Decoder）。

#### **3.3.1.1 编码端（Encoder-Only）架构**

**编码端架构模型：**
- 代表模型包括BERT、RoBERTa等。
- 生成上下文向量表征，用于自然语言理解任务，如情感分析和自然语言推理。

**任务示例：**
- 以情感分析和自然语言理解任务为例，展示了编码端模型的输入输出形式。

#### **3.3.1.2 解码器（Decoder-Only）架构**

**解码器架构模型：**
- 代表模型为GPT系列，是自回归语言模型。
- 能够自然地生成完成文本，适用于自动补全任务。

**任务示例：**
- 以自动补全任务为例，展示了解码器模型的输入输出形式。

#### **3.3.1.3 编码-解码端（Encoder-Decoder）架构**

**编码-解码端架构模型：**
- 代表模型包括Transformer、BART、T5等。
- 结合了编码端和解码端的优点，能够处理输入和生成输出。

**任务示例：**
- 以表格到文本生成任务为例，展示了编码-解码端模型的输入输出形式。

**优缺点分析：**
- 编码端优势在于更好地理解文本上下文，解码端能够自然生成文本，而编码-解码端结合了双向上下文依赖和生成文本的优点。

总体而言，这一段详细解释了不同语言模型架构的特点、应用以及它们在特定任务上的表现。

### **3.3.2 语言模型理论**

**深度学习语言模型理论 - Transformer架构详解**

1. **Transformer架构概述**
   - Transformer是一种基于自注意力机制的神经网络架构，由Vaswani等人于2017年提出。
   - 具有良好的并行化能力，相较于传统的RNN和LSTM在处理序列数据时更为高效，成为自然语言处理任务中的关键工具。

2. **注意力机制**
   - **自注意力机制**
     - 用于为序列中不同位置的词元分配不同的权重，允许模型关注整个输入序列。
     - 包括查询（Query）、键（Key）、值（Value）向量的线性变换，通过点积和softmax计算权重，形成最终的注意力输出。
   - **多头注意力**
     - 引入多头注意力机制，通过并行学习多种关系，将多个注意力头的输出拼接并线性变换，形成最终的输出。

3. **残差连接和归一化**
   - **残差连接**
     - 通过将输入添加到网络层的输出，防止梯度消失问题，有助于更有效的训练。
   - **归一化**
     - 通过对输入进行归一化，保持网络层输出的稳定性，防止梯度爆炸或梯度消失问题。

4. **位置嵌入**
   - 引入位置嵌入，将关于词元位置的信息嵌入到词嵌入中，解决Transformer对输入序列中位置不敏感的问题。

5. **GPT-3架构**
   - GPT-3是基于Transformer的大规模语言模型，包含96个Transformer块，每个块由多头注意力、前馈神经网络和残差连接组成。
   - 架构经过精心设计，考虑了隐藏状态维度、前馈层维度、注意头数量和上下文长度等因素。

6. **深入Transformer的核心组件**
   - **位置嵌入：** 将位置信息嵌入词嵌入中，使模型能够理解序列中的相对位置。
   - **自注意力机制：** 通过查询、键、值向量的计算和加权输出，实现对不同位置的信息关注。
   - **多头注意力机制：** 并行学习不同关系，通过拼接和线性变换得到多头注意力的最终输出。
   - **残差连接和层归一化：** 确保梯度的稳定传播，使训练过程更加稳定。
   - **前馈神经网络：** 处理自注意力机制的输出，有助于学习更复杂的语义表示。
   - **学习率调度：** 动态调整学习率以适应模型的参数数量和训练进程。
   - **遮掩机制：** 在训练中防止模型获取未来信息，确保每个词元的生成只使用之前的信息。

通过理解这些组件，我们更深刻地认识了Transformer如何处理序列数据、捕捉长距离依赖关系，以及在自然语言处理任务中的卓越性能。


## 第四章 新的模型架构

这里讲述了神经语言模型的核心接口、GPT-3模型的架构、当前模型规模扩展的问题，以及提出了两种新型模型架构的思考。其中，混合专家模型介绍了一组专家，每个输入只激活其中一小部分，类似于咨询委员会的专业分工。基于检索的模型则利用原始数据存储库，通过检索相关数据来预测输出，类似于进行网络搜索以获取答案。整体而言，这些讨论反映了对于构建更大规模语言模型的挑战和新的思考方向。

### 4.1专家模型

**混合专家模型**

* **基础知识**
    - **神经语言模型的核心接口**
        - 映射token序列到上下文嵌入的编码器
        - 以GPT-3为例，通过堆叠96层Transformer block实现

* **大模型之问题**
    - **规模扩大的挑战**
        - 模型规模已达极限
        - 网络带宽成为训练瓶颈

* **新的模型架构**
    1. **混合专家模型**
        - **基础概念**
            - 源自Jacobs et al. (1991)
            - 针对预测问题，引入混合专家的思想
        - **模型结构**
            - 多个专家，每个专家激活一小部分，类似咨询委员会
            - 通过概率分布的门控函数进行专家的激活
        - **训练**
            - 利用反向传播学习混合专家模型
            - 随机保留激活专家
        - **优势**
            - 适合并行化，每个专家可在不同机器上
    2. **基于检索的模型**
        - **思想**
            - 利用原始数据存储库，检索与新输入相关的数据预测输出
            - 类比于网络搜索的过程
        - **模型结构**
            - 存储库、输入、输出之间的关系
        - **应用**
            - 针对特定问题，检索存储库中相关数据进行预测

* **实例模型**
    1. **Sparsely-gated mixture of experts (Lepikhin et al. 2021)**
        - 应用混合专家思想于语言模型
        - 每个token、每层Transformer block使用MoE前馈网络
        - 利用top-2专家的近似门控函数
    2. **Switch Transformer (Fedus et al. 2021)**
        - 使用top-1专家，采用近似门控函数
        - 利用FP16、小参数初始化、专家dropout等技巧
        - 训练1.6万亿参数模型
    3. **Balanced Assignment of Sparse Experts (BASE) layers (Lewis et al., 2021)**
        - 使用联合优化，为每个token分配1名专家
        - 考虑负载平衡作为约束
    4. **Generalist Language Model (GLaM) (Du et al. 2021)**
        - 参数规模1.2万亿，64专家，64层，32K隐藏单元
        - 新数据集GLaM dataset
        - 在各项任务中实现0-shot和1-shot性能优于GPT-3
    5. **FacebookMoE (Artetxe et al., 2021)**
        - 1.1T参数模型，512专家，32层，4096隐藏单元
        - 训练使用1120亿token数据集
        - 在StereoSet上表现，对刻板印象的处理较为糟糕
    6. **Decentralized mixture-of-experts (Ryabinin & Gusev, 2020)**
        - 考虑节点众多、频繁故障、家庭互联网通信带宽等因素
        - 使用分布式哈希表进行节点通信
        - 模型结构包含top-4专家
    7. **Diskin et al., 2021**
        - 40名志愿者训练ALBERT掩码语言模型
        - 使用分布式计算，任何人可以加入并贡献计算

* **总结**
    - **混合专家模型**
        -

 解决大规模模型的挑战
        - 通过引入稀疏性和分布式计算提高训练效率
        - 在各种任务和数据集中取得显著性能
    - **未来展望**
        - 深入研究混合专家的不同变体
        - 在更广泛的领域和任务中验证性能
        - 考虑实际应用中的资源和计算限制

### **4.2 基于检索的模型**

基于检索的语言模型的原理涉及两个关键阶段：检索和生成。以下是该模型的基本原理：

**检索阶段：**

1. **存储库（Repository）：** 模型事先构建了一个包含大量序列（文档、段落等）的存储库，记为 S。这个存储库充当了模型获取信息的来源。

2. **检索器（Retriever）：** 当模型接收到输入文本 x（例如一个问题），检索器的任务是从存储库中选择与输入最相关的序列 z。检索器的选择可以基于相似性度量，如使用预训练的语言模型（例如BERT）计算输入与存储库序列之间的相似性。

**生成阶段：**

1. **生成器（Generator）：** 在检索阶段选择的序列 z 和输入文本 x 的基础上，生成器负责产生最终的输出 y。这个生成器可以是一个预训练的语言模型，比如BART（基于编码器-解码器结构）。

2. **综合概率计算：** 生成阶段的概率计算基于两个概率因素的乘积。首先，是检索器选择序列 z 的概率（p(z∣x)），其次，是生成器产生输出 y 的概率（p(y∣z,x)）。整个过程的概率计算可以表示为∑z∈S p(z∣x) * p(y∣z,x)，即从存储库中选择序列并生成输出的总体概率。

这种基于检索的模型允许模型在处理输入时参考大量的背景信息，提高了对特定任务的适应性。同时，它还具备一定的可解释性，因为生成的结果可以追溯到检索到的具体信息。这种模型的应用范围广泛，特别适用于知识密集型任务，如开放问答。

### **4.3 总体总结**

- 为了扩大模型规模，需要改进稠密Transformer。
- 混合专家和基于检索的方法相结合更有效。
- 如何设计更好的、可扩展的体系结构仍然是一个悬而未决的问题。




